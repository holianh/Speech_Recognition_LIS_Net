{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36564bitvirtualenv608955cc4e504b1faebd62d78a85a7f3",
   "display_name": "Python 3.6.5 64-bit (virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "#author:zhangwei\n",
    "\n",
    "'''\n",
    "   此脚本是采用Densenet网络构建端到端声学模型，目前最好的识别效果是32.27%;\n",
    "'''\n",
    "\n",
    "from general_function.file_wav import *\n",
    "from general_function.file_wav import *\n",
    "from general_function.file_dict import *\n",
    "from general_function.feature_extract import *\n",
    "from general_function.edit_distance import *\n",
    "\n",
    "import keras as kr\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Dense , Dropout , Input , Reshape , multiply\n",
    "from keras.layers import Conv2D , MaxPooling2D , Lambda , Activation , regularizers , AveragePooling2D , concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD , Adadelta , Adam\n",
    "from keras.layers.advanced_activations import ELU, LeakyReLU\n",
    "\n",
    "from readdata_densenet_01 import DataSpeech\n",
    "\n",
    "class ModelSpeech():\n",
    "    def __init__(self , datapath):\n",
    "        MS_OUTPUT_SIZE = 1422\n",
    "        k1, k2, k3 = 8, 16, 32\n",
    "        self.MS_OUTPUT_SIZE = MS_OUTPUT_SIZE\n",
    "        self.label_max_string_length = 64\n",
    "        self.AUDIO_LENGTH = 1600\n",
    "        self.AUDIO_FEATURE_LENGTH = 360\n",
    "        self.k1, self.k2, self.k3 = k1, k2, k3\n",
    "        self.datapath = datapath\n",
    "        self._model , self.base_model = self.creat_model()\n",
    "        # self.droprate = 0.3\n",
    "\n",
    "        self.slash = '/'\n",
    "        if self.datapath[-1] != self.slash:\n",
    "            self.datapath = self.datapath + self.slash\n",
    "        pass\n",
    "\n",
    "    def creat_model(self):\n",
    "        input_data = Input(shape=[self.AUDIO_LENGTH , self.AUDIO_FEATURE_LENGTH , 1] , name='Input')\n",
    "        # x = input_data\n",
    "        conv1 = Conv2D(filters=32, kernel_size=[3, 3] , padding='same' , use_bias=True , kernel_initializer='he_normal')(input_data)\n",
    "        conv1 = BatchNormalization()(conv1)\n",
    "        conv1 = Activation(activation='relu')(conv1)\n",
    "        # conv1 = Conv2D(filters=64, kernel_size=[3, 3] , padding='same' , use_bias=True , kernel_initializer='he_normal')(activ_1)\n",
    "        # conv1 = BatchNormalization()(conv1)\n",
    "        # conv1 = Activation(activation='relu')(conv1)\n",
    "        x = MaxPooling2D(pool_size=[1, 1], strides=None, padding='valid')(conv1)\n",
    "        x= Dropout(rate=0.3)(x)\n",
    "\n",
    "        b1_1 = self.dense_block(x, self.k1)\n",
    "        b1_1_conc = concatenate([x, b1_1], axis=-1)\n",
    "        b1_2 = self.dense_block(b1_1_conc, self.k1)\n",
    "        b1_2_conc = concatenate([x, b1_1, b1_2], axis=-1)\n",
    "        b1_3 = self.dense_block(b1_2_conc, self.k1)\n",
    "        b1_3_conc = concatenate([x, b1_1, b1_2, b1_3], axis=-1)\n",
    "        b1_4 = self.dense_block(b1_3_conc, self.k1)\n",
    "        b1_4_conc = concatenate([x, b1_1, b1_2, b1_3, b1_4], axis=-1)\n",
    "        b1_5 = self.dense_block(b1_4_conc, self.k1)\n",
    "        b1_5_conc = concatenate([x, b1_1, b1_2, b1_3, b1_4, b1_5], axis=-1)\n",
    "        transion_1 = self.transition_layer(b1_5_conc, self.k1)\n",
    "\n",
    "        b2_1 = self.dense_block(transion_1, self.k2)\n",
    "        b2_1_conc = concatenate([transion_1, b2_1], axis=-1)\n",
    "        b2_2 = self.dense_block(b2_1_conc, self.k2)\n",
    "        b2_2_conc = concatenate([transion_1, b2_1, b2_2], axis=-1)\n",
    "        b2_3 = self.dense_block(b2_2_conc, self.k2)\n",
    "        b2_3_conc = concatenate([transion_1, b2_1, b2_2, b2_3], axis=-1)\n",
    "        b2_4 = self.dense_block(b2_3_conc, self.k2)\n",
    "        b2_4_conc = concatenate([transion_1, b2_1, b2_2, b2_3, b2_4], axis=-1)\n",
    "        b2_5 = self.dense_block(b2_4_conc, self.k2)\n",
    "        b2_5_conc = concatenate([transion_1, b2_1, b2_2, b2_3, b2_4, b2_5], axis=-1)\n",
    "        transion_2 = self.transition_layer(b2_5_conc, self.k2)\n",
    "\n",
    "        b3_1 = self.dense_block(transion_2, self.k3)\n",
    "        b3_1_conc = concatenate([transion_2, b3_1], axis=-1)\n",
    "        b3_2 = self.dense_block(b3_1_conc, self.k3)\n",
    "        b3_2_conc = concatenate([transion_2, b3_1 , b3_2], axis=-1)\n",
    "        b3_3 = self.dense_block(b3_2_conc, self.k3)\n",
    "        b3_3_conc = concatenate([transion_2, b3_1 , b3_2 , b3_3], axis=-1)\n",
    "        b3_4 = self.dense_block(b3_3_conc, self.k3)\n",
    "        b3_4_conc = concatenate([transion_2, b3_1 , b3_2 , b3_3 , b3_4], axis=-1)\n",
    "        b3_5 = self.dense_block(b3_4_conc, self.k3)\n",
    "        b3_5_conc = concatenate([transion_2, b3_1 , b3_2 , b3_3 , b3_4 , b3_5], axis=-1)\n",
    "        transion_3 = self.transition_layer(b3_5_conc, self.k3)\n",
    "\n",
    "        reshape_layer = Reshape([200, 1440])(transion_3)\n",
    "\n",
    "        # dense1 = Dense(units=512, use_bias=True , kernel_initializer='he_normal')(reshape_layer)\n",
    "        # dense1 = BatchNormalization()(dense1)\n",
    "        # dense1 = Activation(activation='relu')(dense1)\n",
    "        # dense1 = Dropout(rate=0.3)(dense1)\n",
    "\n",
    "        dense2 = Dense(units=1024, use_bias=True , kernel_initializer='he_normal')(reshape_layer)\n",
    "        dense2 = BatchNormalization()(dense2)\n",
    "        dense2 = Activation(activation='relu')(dense2)\n",
    "        dense2 = Dropout(rate=0.3)(dense2)\n",
    "\n",
    "        dense3 = Dense(units=self.MS_OUTPUT_SIZE , use_bias=True)(dense2)\n",
    "        y_pred = Activation(activation='softmax')(dense3)\n",
    "\n",
    "        model_data = Model(inputs=input_data , outputs=y_pred)\n",
    "\n",
    "        # model_data.summary()\n",
    "        # plot_model(model_data, '/home/zhangwei/01.png' , show_shapes=True)\n",
    "\n",
    "        labels = Input(shape=[self.label_max_string_length], name='labels', dtype='float32')\n",
    "        input_length = Input(shape=[1], name='input_length', dtype='int64')\n",
    "        label_length = Input(shape=[1], name='label_length', dtype='int64')\n",
    "        loss_out = Lambda(self.ctc_lambda_func, output_shape=[1, ], name='ctc')([y_pred , labels, input_length, label_length])\n",
    "        model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "        sgd = SGD(lr=0.00001, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "        ada_d = Adadelta(lr=0.0005 , rho=0.95, epsilon=1e-6)\n",
    "        adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "        model.compile(optimizer=adam , loss={'ctc': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "        print('==========================模型创建成功=================================')\n",
    "        return model, model_data\n",
    "\n",
    "    def dense_block(self , input_tensor , channels):\n",
    "        # bn1 = BatchNormalization()(input_tensor)\n",
    "        # relu = Activation(activation='relu')(bn1)\n",
    "        # conv1 = Conv2D(filters= channels, kernel_size=[1, 1], padding='same' , use_bias=True , kernel_initializer='he_normal')(relu)\n",
    "        bn2 = BatchNormalization()(input_tensor)\n",
    "        relu2 = Activation(activation='relu')(bn2)\n",
    "        conv2 = Conv2D(filters=channels, kernel_size=[3, 3], padding='same' , use_bias=True , kernel_initializer='he_normal')(relu2)\n",
    "        return conv2\n",
    "\n",
    "    def dense_block_B(self , input_tensor , channels):\n",
    "        bn1 = BatchNormalization()(input_tensor)\n",
    "        relu = Activation(activation='relu')(bn1)\n",
    "        conv1 = Conv2D(filters=4 * channels, kernel_size=[1, 1], padding='same' , use_bias=True , kernel_initializer='he_normal')(relu)\n",
    "        bn2 = BatchNormalization()(conv1)\n",
    "        relu2 = Activation(activation='relu')(bn2)\n",
    "        conv2 = Conv2D(filters=channels, kernel_size=[3, 3], padding='same' , use_bias=True , kernel_initializer='he_normal')(relu2)\n",
    "        return conv2\n",
    "\n",
    "    def transition_layer(self , input_tensor , channels):\n",
    "        bn1 = BatchNormalization()(input_tensor)\n",
    "        relu1 = Activation(activation='relu')(bn1)\n",
    "        conv = Conv2D(filters=channels , kernel_size=[1, 1], padding='same' , use_bias=True , kernel_initializer='he_normal')(relu1)\n",
    "        pool = MaxPooling2D(pool_size=[2, 2], strides=[2, 2])(conv)\n",
    "        pool = Dropout(rate=0.3)(pool)\n",
    "        return pool\n",
    "\n",
    "    def ctc_lambda_func(self , args):\n",
    "        y_pred , labels , input_length , label_length = args\n",
    "        y_pred = y_pred[: , : , :]\n",
    "        return K.ctc_batch_cost(y_true=labels , y_pred=y_pred , input_length=input_length , label_length=label_length)\n",
    "\n",
    "    def train_model(self , datapath , epoch=4 , save_step=2000 , batch_size=1):\n",
    "        data = DataSpeech(datapath , 'train')\n",
    "        num_data = data.get_datanum()\n",
    "        yielddatas = data.data_generator(batch_size , self.AUDIO_LENGTH)\n",
    "        for epoch in range(epoch):\n",
    "            print('[*running] train epoch %d .' % epoch)\n",
    "            n_step = 0\n",
    "            while True:\n",
    "                try:\n",
    "                    print('[*message] epoch %d , Having training data %d+' % (epoch , n_step * save_step))\n",
    "                    self._model.fit_generator(yielddatas , save_step)\n",
    "                    n_step += 1\n",
    "                except StopIteration:\n",
    "                    print('======================Error StopIteration==============================')\n",
    "                    break\n",
    "                self.save_model(comments='_e_' + str(epoch) + '_step_' + str(n_step * save_step))\n",
    "                self.test_model(datapath=self.datapath , str_dataset='train' , data_count=4)\n",
    "                self.test_model(datapath=self.datapath , str_dataset='dev' , data_count=16)\n",
    "\n",
    "    def load_model(self, filename='model_speech_e_0_step_16000.model'):\n",
    "        self._model.load_weights(filename)\n",
    "        self.base_model.load_weights(filename + '.base')\n",
    "\n",
    "    def test_model(self , datapath='' , str_dataset='dev' , data_count=1):\n",
    "        data = DataSpeech(self.datapath , str_dataset)\n",
    "        num_data = data.get_datanum()\n",
    "        # print num_data\n",
    "        if data_count <=0 and data_count > num_data:\n",
    "            data_count = num_data\n",
    "        try:\n",
    "            ran_num = random.randint(0 , num_data - 1)\n",
    "            words_num = 0.\n",
    "            word_error_num = 0.\n",
    "            for i in range(data_count):\n",
    "                data_input , data_labels = data.get_data((ran_num + i) % num_data)\n",
    "                # print data_input\n",
    "                num_bias = 0\n",
    "                while data_input.shape[0] > self.AUDIO_LENGTH:\n",
    "                    print('[*Error] data input is too long %d' % ((ran_num + i) % num_data))\n",
    "                    num_bias += 1\n",
    "                    data_input , data_labels = data.get_data((ran_num + i + num_bias) % num_data)\n",
    "\n",
    "                pre = self.predict(data_input=data_input , input_len=data_input.shape[0] // 8)                   #1\n",
    "                words_n = data_labels.shape[0]\n",
    "                words_num += words_n\n",
    "                edit_distance = get_edit_distance(data_labels , pre)\n",
    "                if edit_distance <= words_n:\n",
    "                    word_error_num += edit_distance\n",
    "                else:\n",
    "                    word_error_num += words_n\n",
    "            # print type(words_num)\n",
    "            print('[*Test Result] Speech Recognition ' + str_dataset + ' set word error ratio : ' + str(word_error_num / words_num * 100) , '%')\n",
    "        except StopIteration:\n",
    "            print('=======================Error StopIteration 01======================')\n",
    "\n",
    "    def save_model(self , filename='/home/zhangwei/speech_model/speech_model' , comments=''):\n",
    "        self._model.save_weights(filename + comments + '.model')\n",
    "        self.base_model.save_weights(filename + comments + '.model.base')\n",
    "        f = open('steps24.txt' , 'w')\n",
    "        f.write(filename + comments)\n",
    "        f.close()\n",
    "\n",
    "    def predict(self , data_input , input_len):\n",
    "        batch_size = 1\n",
    "        in_len = np.zeros((batch_size) , dtype=np.int32)\n",
    "        in_len[0] = input_len\n",
    "        x_in = np.zeros(shape=[batch_size , self.AUDIO_LENGTH , self.AUDIO_FEATURE_LENGTH , 1] , dtype=np.float)\n",
    "        for i in range(batch_size):\n",
    "            x_in[i , 0 : len(data_input)] = data_input\n",
    "        base_pred = self.base_model.predict(x=x_in)\n",
    "        base_pred = base_pred[: , : , :]\n",
    "        r = K.ctc_decode(base_pred , in_len , greedy=True , beam_width=100 , top_paths=1)\n",
    "        r1 = K.get_value(r[0][0])\n",
    "        r1 = r1[0]\n",
    "        return r1\n",
    "\n",
    "    def recognize_speech(self , wavsignal , fs):\n",
    "        data_input = get_frequency_feature(wavsignal , fs)\n",
    "        input_length = len(data_input)\n",
    "        input_length = input_length // 8                  #2\n",
    "        data_input = np.array(data_input , dtype=np.float)\n",
    "        data_input = data_input.reshape(data_input.shape[0] , data_input.shape[1] , 1)\n",
    "        r1 = self.predict(data_input , input_length)\n",
    "        # print r1\n",
    "        list_symbol_dic = get_list_symbol(self.datapath)\n",
    "        r_str = []\n",
    "        for i in r1:\n",
    "            r_str.append(list_symbol_dic[i])\n",
    "        return r_str\n",
    "\n",
    "    def recognize_speech_fromfile(self , filename):\n",
    "        wavsignal , fs = read_wav_data(filename)\n",
    "        r = self.recognize_speech(wavsignal , fs)\n",
    "        return r\n",
    "\n",
    "    def recognize_speech_pinzhen(self , wavsignal , fs):\n",
    "        data_input = get_frequency_feature(wavsignal , fs)\n",
    "        input_length = len(data_input)\n",
    "        input_length = input_length // 8                                                                 #2\n",
    "        data_input = np.array(data_input , dtype=np.float)\n",
    "        data_input = data_input.reshape(data_input.shape[0] , data_input.shape[1] , 1)\n",
    "        r1 = self.predict(data_input , input_length)\n",
    "        # print r1\n",
    "        list_symbol_dic = get_list_symbol(self.datapath)\n",
    "        r_str = []\n",
    "        for i in r1:\n",
    "            r_str.append(list_symbol_dic[i])\n",
    "        return r_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2.2.4\n"
    }
   ],
   "source": [
    "from keras.layers import Conv2D , MaxPooling2D , Lambda , Activation , regularizers , AveragePooling2D , concatenate\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep notebook alive\n",
    "Set a javascript interval to click on the connect button every 60 seconds. Open developer-settings (in your web-browser) with Ctrl+Shift+I then click on console tab and type this on the console prompt. (for mac press Option+Command+I)\n",
    "\n",
    "```\n",
    "function ConnectButton(){\n",
    "    console.log(\"Connect pushed\"); \n",
    "    document.querySelector(\"#connect\").click() \n",
    "}\n",
    "setInterval(ConnectButton,60000);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Javascript\n",
    "def MaxCellHeight(mHeight=300):\n",
    "    display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: mHeight})'''))\n",
    "MaxCellHeight()\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp \"/content/drive/My Drive/Deeplearning/thch30_train_dev_test.zip\"  \"thch30_train_dev_test.zip\" \n",
    "!unzip -qq thch30_train_dev_test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.90\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "datapath = 'data_thchs30'\n",
    "speech = ModelSpeech(datapath=datapath)\n",
    "# speech.creat_model()\n",
    "speech.train_model(datapath=datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'_e_2_step_55\\r\\ntttttttttttttttttt\\n\\ruuuuuuuuuuuuuuuuuu'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strain,sdev__=\"\", \"\"\n",
    "epoch=2\n",
    "\n",
    "strain=\"tttttttttttttttttt\"\n",
    "sdev__=\"uuuuuuuuuuuuuuuuuu\"\n",
    "comment=\"_e_{}_step_{}\\r\\n{}\\n\\r{}\".format(epoch, 55 ,strain,sdev__ )\n",
    "comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}